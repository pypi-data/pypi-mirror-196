Metadata-Version: 2.1
Name: HITrack
Version: 1.0.4
Summary: 3D scene on a monocular video
Home-page: https://github.com/Kirill-Shokhin/HITrack
Author: Kirill Shokhin
Author-email: kashokhin@gmail.com
License: MIT
Keywords: HITrack
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE

# HITrack

**HITrack** or **Human Inertial Tracking** is a pipeline consisting of 3 human recognition state-of-the-art neural networks 
([yolov7](https://github.com/WongKinYiu/yolov7), 
[VitPose](https://github.com/ViTAE-Transformer/ViTPose) and 
[MHFormer](https://github.com/Vegetebird/MHFormer)) 
linked together by specially designed **Inertial Tracking** to produce a 3D scene on a monocular image.

## Quick start

```
pip install HITrack
```

```python
from HITrack import HITrack
hit = HITrack('videos/dance.mp4')

# 2D keypoints + tracking
hit.compute_2d(yolo='yolov7x', vitpose='b')

# merging recovered tracks and broken tracks manually
hit.recover_2d({2:4, 3:5})

# 2D to 3D by tracking
hit.compute_3d()

# 3D to scene
hit.compute_scene()

# visualising any of these steps
hit.visualize('3D_scene', compress=True, original_sound=True)
```

## License
This project is licensed under the terms of the MIT license.
