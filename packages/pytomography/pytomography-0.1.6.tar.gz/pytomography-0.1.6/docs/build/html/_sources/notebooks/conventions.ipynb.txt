{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates\n",
    "\n",
    "Our choice of cartesian coordinate system is the same as the DICOM standard, where $x$ points from patient right to patient left, $y$ points from anterior to posterior, and $z$ points from inferior to superior.\n",
    "\n",
    "\n",
    "A positive scanner angle $\\beta$ in the DICOM standard is defines as a counterclockwise rotation of angle $\\beta$ from 12 o'clock when looking into the scanner. When compared to the standard azimuthal angle our defined cartesian coordinate system, it follows that $\\phi = 3 \\pi / 2 - \\beta$. Since $\\beta$ is defined in the range $[0, 2\\pi]$ it follows that $\\phi$ is defined in the range $[-\\pi/2, 3\\pi/2]$.\n",
    "\n",
    "There are two primary coordinate systems considered here\n",
    "\n",
    "1. **Cartesian**: Specified by the $x$, $y$, and $z$ coordinates above. Any item in this coordinate system is referred to as an **Object**\n",
    "2. **Sinogram**: Specified by $r$, $\\beta$, and $z$. Sinogram space is used to represent a series of 2D scans (in the $r-z$ plane) at different angles $\\beta$. Any item in this coordinate system are referred to as **Image**.\n",
    "\n",
    "As a convention, $r$ is aligned with the $x$-axis at $\\beta=0$. (Note this implies that $r$ is aligned with the negative $y$-axis at $\\beta=90^{\\circ}$. which can be counterintuitive when viewing images)\n",
    "\n",
    "<img src=\"../images/coordinate_conventions.png\"  width=\"300\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "\n",
    "Objects and images are stored using pytorch tensors. The dimensions of objects are $[B, L_x, L_y, L_z]$ and the dimensions of images are $[B, L_{\\theta}, L_{r}, L_z]$ where $B$ specifies a batch size dimension. When reconstructing multiple objects, using batches may computational time. Batches can also be used to store images taken at different energy windows in SPECT. \n",
    "\n",
    "The index of an object tensor gives a correpsonding voxel in object space; the index of an image tensor gives a corresponding pixel in image space. Indices are arranged such that smaller indices correspond to smaller coordinate values. For example, `object_tensor[0,-1,0,0]` gives the voxel at the largest value of $x$, and the smallest values of $y$ and $z$. As another example, `image_tensor[0,10,0,-1]` gives the pixel at the 10th detector angle corresponding to the smallest value of $r$ and the largest value of $z$.\n",
    "\n",
    "When configuring data for reconstruction in this software, it is important that that all objects and projections are aligned properly along the various axes. When importing your own data, this can be achieved through a combination of transposing and inverting axes. For example, a plot of a projection at $\\beta=90^{\\circ}$ with $r$ as the horizontal axis and $z$ as the vertical axis should have the patient looking to the right (see coordinate system above). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematics\n",
    "\n",
    "Throughout tutorials and documentation, mathematical notation is often used to represent different operations. In this section we define some of the notation. Unless otherwise spcified, the symbols refer to the following:\n",
    "\n",
    "* $f$ refers to an object, and $f_i$ refers to the value of the object at voxel $i$\n",
    "* $g$ refers to an object, and $f_j$ refers to the value of the object at voxel $j$\n",
    "* $c_{ij}$ represents the system matrix operator, which quantifies the contribution of voxel $i$ in object space to detector element $j$ in image space\n",
    "\n",
    "Note that $f_i$ is still represented by a four dimensional tensor, as specified in the previous section (as is $g_j$). The system matrix is never explicitly represented by a tensor (it is very large, and there are tricks we can use to simulate the operation of the system matrix without actually using matrix operations).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations\n",
    "\n",
    "### Projections\n",
    "\n",
    "PyTomography is built around two fundamental operations used in image reconstruction: **Forward Projection** and **Back Projection**.\n",
    "\n",
    "* **Forward Projection**: Takes something in object space and converts it to something in image space using the system matrix: $b_j = \\sum_{i} c_{ij} a_i$. This operation is implemented in the class `ForwardProjectionNet` from `pytomography.projections`. \n",
    "\n",
    "* **Back Projection**: Takes something in image space and converts it to something in object space using the system matrix: $a_i' = \\frac{1}{\\sum_j c_{ij}}\\sum_{j} c_{ij} b_j$. This operation is implemented in the class `BackProjectionNet` from `pytomography.projections`. \n",
    "\n",
    "It's worth noting that $a_i$ and $b_j$ don't have to represent physical objects or images. In the case of the OSEM algorithm, it is the ratio of two quantities that is forward projected: such a ratio does not represent a physical object.\n",
    "\n",
    "### Correction Networks\n",
    "Add\n",
    "\n",
    "### Reconstruction Algorithms\n",
    "Add"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "324f5aa1485c6e81c0125c86ad1340c603dab08bc11babd97bd730cfafa2ec4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
