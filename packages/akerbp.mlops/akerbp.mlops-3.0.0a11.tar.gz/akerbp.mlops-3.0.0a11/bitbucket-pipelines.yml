#  Deployment Pipeline
#
#  Developer notes:
#    - An environment can only be defined in one step per pipeline
#    - Each step is an independent run of the docker image (i.e. envs defined
#       or file transformations are not kept)
#    - Files can be shared between steps if they're defined as artifacts
#    - We could build a custom image for faster deployments

image: python:3.8.5

clone:
  depth: full
  lfs: true

definitions:
  steps:
    - step: &deploy-test-package
        name: Deploy Pre-release to Test
        deployment: test-pypi
        caches:
          - pip
        script:
          - git pull
          - bash -ex build.sh
    - step: &deploy-test-prediction-service
        name: Deploy Prediction Service to Test
        deployment: test-prediction
        caches:
          - pip
        script:
          - git pull
          - bash -ex install.sh
          - deploy_prediction_service
    - step: &upload-artifacts-to-cdf
        name: Upload Artifacts to CDF
        caches:
          - pip
        script:
          - git pull
          - bash -ex install.sh
          - python upload_dummy_artifacts.py
    - step: &run-tests-without-deploying
        name: Run tests without deploying
        caches:
          - pip
        script:
          - git pull
          - bash -ex install.sh
          - export ENV=test
          - TESTING_ONLY=True deploy_prediction_service
    - step: &unit-testing
        name: Unit Testing
        caches:
          - pip
        script:
          - export ENV=test
          - export SERVICE_NAME=prediction
          - git pull
          - bash -ex install.sh
          - pip install coverage
          - coverage run -m pytest test/ -v -ra
          - coverage report
    - step: &flake8-linting
        name: Linting
        caches:
          - pip
        script:
          - pip install flake8
          - flake8 .
    - step: &mypy-type-checking
        name: Type Checking
        caches:
          - pip
        script:
          - git pull
          - bash -ex install.sh
          - pip install mypy
          - pip install pydantic
          - pip install types-PyYAML
          - mypy
    - step: &security-scan-secrets
        name: Security Scan for Secrets
        script:
          - pipe: atlassian/git-secrets-scan:0.5.1
    - step: &snyk-scan
        name: Snyk Scan for Vulnerabilities
        caches:
          - pip
        script:
          - git pull
          - bash -ex install.sh
          - pip freeze > requirements.txt
          - curl https://static.snyk.io/cli/latest/snyk-linux -o snyk
          - chmod +x ./snyk
          - mv ./snyk /usr/local/bin
          - snyk auth $SNYK_TOKEN
          - snyk test --fail-on=all

pipelines:
  pull-requests:
    "**": # Run for PRs on all branches - Deploy pre-release package and prediction services to test
      - parallel:
          - step: *unit-testing
          - step: *flake8-linting
          - step: *mypy-type-checking
          - step: *security-scan-secrets
          - step: *snyk-scan
      - step: *deploy-test-package
      - step: *upload-artifacts-to-cdf
      - step: *run-tests-without-deploying
      - step: *deploy-test-prediction-service

  branches:
    master: # Mirror to public repo and choose to manually deploy package, training and production services to prod
      - step: *unit-testing
      - step:
          name: Mirror Latest Version to Public Repo
          script:
            - git remote add public git@bitbucket.org:akerbp/akerbp.mlops.git
            - git pull
            - git push public master
      - step: &deploy-production-package
          <<: *deploy-test-package
          name: Deploy Package to Production
          deployment: production-pypi
          trigger: manual
      - step:
          <<: *upload-artifacts-to-cdf
          name: Upload Artifacts to Production CDF
          deployment: production-prediction
          trigger: manual
      - step: &deploy-production-prediction-service
          <<: *deploy-test-prediction-service
          name: Deploy Prediction Service to Production
          deployment: production-prediction
          trigger: manual
